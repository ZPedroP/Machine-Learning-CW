{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc, roc_curve,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import tree\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395,)\n",
      "(395, 30)\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Load data from CSV file into a DataFrame\n",
    "file_path = './datasets/student-mat.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "column_names = pd.read_csv(file_path, nrows=0, delimiter=';').columns.tolist()\n",
    "\n",
    "# Load the CSV file again, skipping the first row and using it as column names\n",
    "df = pd.read_csv(file_path, skiprows=1, delimiter=';', names=column_names)\n",
    "\n",
    "# Get the column names for features and target using slicing\n",
    "feature_columns = column_names[:-3]\n",
    "target_columns = column_names[-3:]\n",
    "\n",
    "# Split the DataFrame into features (X) and target (y)\n",
    "X = df[feature_columns]\n",
    "y = df[target_columns]\n",
    "\n",
    "print_corr = 0\n",
    "\n",
    "if print_corr:\n",
    "    # Select the three columns you want to compute the correlation for\n",
    "    selected_columns = y[['G1', 'G2', 'G3']]\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = selected_columns.corr()\n",
    "    print(correlation_matrix)\n",
    "\n",
    "# Drop the first two columns of the y dataframe\n",
    "y = y.drop(y.columns[:2], axis=1)\n",
    "\n",
    "# Rename the remaining column to \"Final Grade\"\n",
    "y = y.rename(columns={y.columns[0]: \"Final Grade\"})\n",
    "\n",
    "# Reshape y to a single column\n",
    "y = np.reshape(y, (-1,))\n",
    "\n",
    "# Convert the target into a binary problem\n",
    "y = np.where(y < 10, 0, 1)\n",
    "\n",
    "y = pd.DataFrame(y).squeeze()\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "print(type(y))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 30)\n",
      "(119, 30)\n",
      "(276,)\n",
      "(119,)\n"
     ]
    }
   ],
   "source": [
    "# get training/test splits by `train_test_split` function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Leave the rest of the columns untouched\n",
    ")\n",
    "\n",
    "# Fit the preprocessing pipeline on the training data\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert the transformed data back to DataFrames\n",
    "# Get the feature names after one-hot encoding\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=feature_names, index=X_train.index)\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed, columns=feature_names, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on validation set:\n",
      "\n",
      "{'ccp_alpha': 1}\n",
      "\n",
      "Grid scores on validation set:\n",
      "\n",
      "0.667 (+/-0.030) for {'ccp_alpha': 1}\n",
      "0.667 (+/-0.030) for {'ccp_alpha': 0.1}\n",
      "0.666 (+/-0.144) for {'ccp_alpha': 0.01}\n",
      "0.595 (+/-0.151) for {'ccp_alpha': 0.001}\n",
      "0.595 (+/-0.151) for {'ccp_alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# set tuning values\n",
    "tuned_parameters = [{\"ccp_alpha\": [1,0.1,0.01,0.001,0.0001]}]\n",
    "treeCV = GridSearchCV(DecisionTreeClassifier(random_state=67), tuned_parameters, scoring='accuracy',cv=20)\n",
    "# more details see https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "treeCV.fit(X_train_preprocessed_df, y_train)\n",
    "print(\"Best parameters set found on validation set:\")\n",
    "print()\n",
    "print(treeCV.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on validation set:\")\n",
    "print()\n",
    "means = treeCV.cv_results_[\"mean_test_score\"]\n",
    "stds = treeCV.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, treeCV.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 30)\n",
      "(119, 30)\n",
      "(276,)\n",
      "(119,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680672268907563"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test set labels\n",
    "ypred_tree = treeCV.predict(X_test_preprocessed_df)\n",
    "accuracy_score(y_test,ypred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth       0   1\n",
       "Predicted        \n",
       "0           0   0\n",
       "1          38  81"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(ypred_tree, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213    0\n",
      "289    1\n",
      "268    1\n",
      "46     1\n",
      "380    1\n",
      "      ..\n",
      "233    1\n",
      "114    0\n",
      "71     1\n",
      "221    0\n",
      "42     1\n",
      "Name: 0, Length: 119, dtype: int64\n",
      "[[0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]\n",
      " [0.33333333 0.66666667]]\n",
      "(119,)\n",
      "(119, 2)\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (119, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y_test))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(yscores_tree))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myscores_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:640\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    639\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    649\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    650\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    654\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/metrics/_base.py:76\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     79\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:387\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n\u001b[0;32m--> 387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1145\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1044\u001b[0m     {\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m ):\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:821\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    819\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    820\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m--> 821\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m    823\u001b[0m assert_all_finite(y_score)\n",
      "File \u001b[0;32m~/.pyenv/versions/fintec/lib/python3.12/site-packages/sklearn/utils/validation.py:1406\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1396\u001b[0m             (\n\u001b[1;32m   1397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1402\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1403\u001b[0m         )\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1408\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (119, 2) instead."
     ]
    }
   ],
   "source": [
    "'''\n",
    "yscores_tree = treeCV.predict_proba(X_test_preprocessed_df) #obtain AUC value\n",
    "print(y_test)\n",
    "print(yscores_tree)\n",
    "print(y_test.shape)\n",
    "print(yscores_tree.shape)\n",
    "print(type(y_test))\n",
    "print(type(yscores_tree))\n",
    "roc_auc_score(y_test, yscores_tree, multi_class=\"ovr\", average=\"micro\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise tree\n",
    "dt = DecisionTreeClassifier(ccp_alpha=0.01,random_state=67)\n",
    "dt_vis=dt.fit(X_train_preprocessed,y_train)\n",
    "fn=X_train_preprocessed_df.columns\n",
    "cn=['0','1']\n",
    "fig, axes = subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "tree.plot_tree(dt_vis,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tuning values\n",
    "tuned_parameters = [{\"max_features\": [5,10,20,30,40,50,\"sqrt\"]}]\n",
    "rfCV = GridSearchCV(RandomForestClassifier(n_estimators=500,bootstrap=True,oob_score=True,random_state=0), tuned_parameters, scoring='accuracy',cv=10)\n",
    "# more details see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "rfCV.fit(X_train_preprocessed_df, y_train)\n",
    "print(\"Best parameters set found on validation set:\")\n",
    "print()\n",
    "print(rfCV.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on validation set:\")\n",
    "print()\n",
    "means = rfCV.cv_results_[\"mean_test_score\"]\n",
    "stds = rfCV.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, rfCV.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set labels\n",
    "ypred_rf = rfCV.predict(X_test_preprocessed_df)\n",
    "accuracy_score(y_test,ypred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table(ypred_tree, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "yscores_rf = rfCV.predict_proba(X_test_preprocessed_df) #obtain AUC value\n",
    "roc_auc_score(y_test,yscores_rf,multi_class=\"ovr\",average=\"micro\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variable importance, e.g. mean decrease in gini index\n",
    "rf = RandomForestClassifier(n_estimators=500,max_features=10,bootstrap=True,oob_score=True,random_state=0).fit(X_train_preprocessed_df,y_train)\n",
    "rf_importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the most important features\n",
    "index = np.argsort(rf_importances)\n",
    "forest_importances = pd.Series(rf_importances[index[-10:]], index=rf.feature_names_in_[index[-10:]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar()\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=3), n_estimators=100, random_state=0)\n",
    "# more details see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "# set tuning values\n",
    "tuned_parameters = [{\"learning_rate\": [0.001,0.01,0.1,1]}]\n",
    "adaCV = GridSearchCV(ada, tuned_parameters, scoring='accuracy',cv=10)\n",
    "adaCV.fit(X_train_preprocessed_df, y_train)\n",
    "print(\"Best parameters set found on validation set:\")\n",
    "print()\n",
    "print(adaCV.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on validation set:\")\n",
    "print()\n",
    "means = adaCV.cv_results_[\"mean_test_score\"]\n",
    "stds = adaCV.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, adaCV.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set labels\n",
    "ypred_ada = adaCV.predict(X_test_preprocessed_df)\n",
    "accuracy_score(y_test,ypred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table(ypred_ada, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "yscores_ada = adaCV.predict_proba(X_test_preprocessed_df) #obtain AUC value\n",
    "roc_auc_score(y_test,yscores_ada,multi_class=\"ovr\",average=\"micro\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = GradientBoostingClassifier(max_depth=3, n_estimators=100, random_state=0)\n",
    "# more details see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "# set tuning values\n",
    "tuned_parameters = [{\"learning_rate\": [0.001,0.01,0.1,1]}]\n",
    "grdCV = GridSearchCV(grd, tuned_parameters, scoring='accuracy',cv=10)\n",
    "grdCV.fit(X_train_preprocessed_df, y_train)\n",
    "print(\"Best parameters set found on validation set:\")\n",
    "print()\n",
    "print(grdCV.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on validation set:\")\n",
    "print()\n",
    "means = grdCV.cv_results_[\"mean_test_score\"]\n",
    "stds = grdCV.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(means, stds, grdCV.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set labels\n",
    "ypred_grd = grdCV.predict(X_test_preprocessed_df)\n",
    "accuracy_score(y_test,ypred_grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table(ypred_grd, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "yscores_grd = grdCV.predict_proba(X_test_preprocessed_df) #obtain AUC value\n",
    "roc_auc_score(y_test,yscores_grd,multi_class=\"ovr\",average=\"micro\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variable importance, e.g. mean decrease in gini index\n",
    "grd = GradientBoostingClassifier(learning_rate=0.01, max_depth=3, n_estimators=100, random_state=0).fit(X_train_preprocessed_df,y_train)\n",
    "grd_importances = grd.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the most important features\n",
    "grd_index = np.argsort(grd_importances)\n",
    "boosting_importances = pd.Series(grd_importances[grd_index[-10:]], index=grd.feature_names_in_[grd_index[-10:]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "boosting_importances.plot.bar()\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
